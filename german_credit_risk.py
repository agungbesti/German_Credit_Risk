# -*- coding: utf-8 -*-
"""German Credit Risk.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1CjXEqstEN_Njlhdiw-oLYS8chCTfHrNG

**Import library dan module yang dibutuhkan**

---
Mengimpor library dan module yang dibutuhkan untuk membuat project ini
"""

# Import libraries
import pandas as pd
#Load the librarys
import pandas as pd #To work with dataset
import numpy as np #Math library
import seaborn as sns #Graph library that use matplot in background
import matplotlib.pyplot as plt #to plot some parameters in seaborn

import warnings
warnings.filterwarnings('ignore')
cmap=sns.color_palette('Blues_r')


from scipy.stats import chi2_contingency
from sklearn.model_selection import train_test_split, KFold, cross_val_score, GridSearchCV                                         # to split the data
from sklearn.metrics import mean_squared_error, r2_score, accuracy_score, confusion_matrix, classification_report, fbeta_score     # to evaluate our model

# Algorithmns models to be compared
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression, LinearRegression, Ridge, Lasso, ElasticNet
from sklearn.tree import DecisionTreeClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
from sklearn.naive_bayes import GaussianNB
from sklearn.svm import SVC
from xgboost import XGBClassifier
from lightgbm import LGBMClassifier

"""Utility script with functions to be used with the results of GridSearchCV.

**plot_grid_search** plots as many graphs as parameters are in the grid search results.

**table_grid_search** shows tables with the grid search results.

Inspired in [Displaying the results of a Grid Search](https://www.kaggle.com/grfiv4/displaying-the-results-of-a-grid-search) notebook,
of [George Fisher](https://www.kaggle.com/grfiv4)
"""

import pandas as pd
from plotly.subplots import make_subplots
import plotly.graph_objs as go
import pprint
from scipy import stats
from IPython.display import display

__author__ = "Juanma Hernández"
__copyright__ = "Copyright 2019"
__credits__ = ["Juanma Hernández", "George Fisher"]
__license__ = "GPL"
__maintainer__ = "Juanma Hernández"
__email__ = "https://twitter.com/juanmah"
__status__ = "Utility script"


def plot_grid_search(clf):
    """Plot as many graphs as parameters are in the grid search results.

    Each graph has the values of each parameter in the X axis and the Score in the Y axis.

    Parameters
    ----------
    clf: estimator object result of a GridSearchCV
        This object contains all the information of the cross validated results for all the parameters combinations.
    """
    # Convert the cross validated results in a DataFrame ordered by `rank_test_score` and `mean_fit_time`.
    # As it is frequent to have more than one combination with the same max score,
    # the one with the least mean fit time SHALL appear first.
    cv_results = pd.DataFrame(clf.cv_results_).sort_values(by=['rank_test_score', 'mean_fit_time'])

    # Get parameters
    parameters=cv_results['params'][0].keys()

    # Calculate the number of rows and columns necessary
    rows = -(-len(parameters) // 2)
    columns = min(len(parameters), 2)
    # Create the subplot
    fig = make_subplots(rows=rows, cols=columns)
    # Initialize row and column indexes
    row = 1
    column = 1

    # For each of the parameters
    for parameter in parameters:

        # As all the graphs have the same traces, and by default all traces are shown in the legend,
        # the description appears multiple times. Then, only show legend of the first graph.
        if row == 1 and column == 1:
            show_legend = True
        else:
            show_legend = False

        # Mean test score
        mean_test_score = cv_results[cv_results['rank_test_score'] != 1]
        fig.add_trace(go.Scatter(
            name='Mean test score',
            x=mean_test_score['param_' + parameter],
            y=mean_test_score['mean_test_score'],
            mode='markers',
            marker=dict(size=mean_test_score['mean_fit_time'],
                        color='SteelBlue',
                        sizeref=2. * cv_results['mean_fit_time'].max() / (40. ** 2),
                        sizemin=4,
                        sizemode='area'),
            text=mean_test_score['params'].apply(
                lambda x: pprint.pformat(x, width=-1).replace('{', '').replace('}', '').replace('\n', '<br />')),
            showlegend=show_legend),
            row=row,
            col=column)

        # Best estimators
        rank_1 = cv_results[cv_results['rank_test_score'] == 1]
        fig.add_trace(go.Scatter(
            name='Best estimators',
            x=rank_1['param_' + parameter],
            y=rank_1['mean_test_score'],
            mode='markers',
            marker=dict(size=rank_1['mean_fit_time'],
                        color='Crimson',
                        sizeref=2. * cv_results['mean_fit_time'].max() / (40. ** 2),
                        sizemin=4,
                        sizemode='area'),
            text=rank_1['params'].apply(str),
            showlegend=show_legend),
            row=row,
            col=column)

        fig.update_xaxes(title_text=parameter, row=row, col=column)
        fig.update_yaxes(title_text='Score', row=row, col=column)

        # Check the linearity of the series
        # Only for numeric series
        if pd.to_numeric(cv_results['param_' + parameter], errors='coerce').notnull().all():
            x_values = cv_results['param_' + parameter].sort_values().unique().tolist()
            r = stats.linregress(x_values, range(0, len(x_values))).rvalue
            # If not so linear, then represent the data as logarithmic
            if r < 0.86:
                fig.update_xaxes(type='log', row=row, col=column)

        # Increment the row and column indexes
        column += 1
        if column > columns:
            column = 1
            row += 1

            # Show first the best estimators
    fig.update_layout(legend=dict(traceorder='reversed'),
                      width=columns * 360 + 100,
                      height=rows * 360,
                      title='Best score: {:.6f} with {}'.format(cv_results['mean_test_score'].iloc[0],
                                                                str(cv_results['params'].iloc[0]).replace('{',
                                                                                                          '').replace(
                                                                    '}', '')),
                      hovermode='closest',
                      template='none')
    fig.show()


def table_grid_search(clf, all_columns=False, all_ranks=False, save=True):
    """Show tables with the grid search results.

    Parameters
    ----------
    clf: estimator object result of a GridSearchCV
        This object contains all the information of the cross validated results for all the parameters combinations.

    all_columns: boolean, default: False
        If true all columns are returned. If false, the following columns are dropped:

        - params. As each parameter has a column with the value.
        - std_*. Standard deviations.
        - split*. Split scores.

    all_ranks: boolean, default: False
        If true all ranks are returned. If false, only the rows with rank equal to 1 are returned.

    save: boolean, default: True
        If true, results are saved to a CSV file.
    """
    # Convert the cross validated results in a DataFrame ordered by `rank_test_score` and `mean_fit_time`.
    # As it is frequent to have more than one combination with the same max score,
    # the one with the least mean fit time SHALL appear first.
    cv_results = pd.DataFrame(clf.cv_results_).sort_values(by=['rank_test_score', 'mean_fit_time'])

    # Reorder
    columns = cv_results.columns.tolist()
    # rank_test_score first, mean_test_score second and std_test_score third
    columns = columns[-1:] + columns[-3:-1] + columns[:-3]
    cv_results = cv_results[columns]

    if save:
        cv_results.to_csv('--'.join(cv_results['params'][0].keys()) + '.csv', index=True, index_label='Id')

    # Unless all_columns are True, drop not wanted columns: params, std_* split*
    if not all_columns:
        cv_results.drop('params', axis='columns', inplace=True)
        cv_results.drop(list(cv_results.filter(regex='^std_.*')), axis='columns', inplace=True)
        cv_results.drop(list(cv_results.filter(regex='^split.*')), axis='columns', inplace=True)

    # Unless all_ranks are True, filter out those rows which have rank equal to one
    if not all_ranks:
        cv_results = cv_results[cv_results['rank_test_score'] == 1]
        cv_results.drop('rank_test_score', axis = 'columns', inplace = True)        
        cv_results = cv_results.style.hide_index()

    display(cv_results)

"""**Mengload Dataset yang akan digunakan dan Proses Cleaning Awal**

---
[Dataset](https://www.kaggle.com/datasets/kabure/german-credit-data-with-risk) yang digunakan pada project ini diperoleh dari dari kaggle. Setelah mengamati beberapa kolom yang terdapat dalam dataset. Ada kolom index yang dapat langsung dieliminasi, karena tidak relevan dengan proses analisis data selanjutnya.
"""

df = pd.read_csv('/content/german_credit_data.csv', index_col=0)
df = df.rename(columns={'Saving accounts': 'Saving_accounts','Checking account':'Checking_account','Credit amount':'Credit_amount'})
df

"""**Deskripsi atribute yang terdapat pada dataset**

---
- Age = Umur pengajuan kredit
- Sex = Jenis kelamin pengajuan
- Job = Jenis pekerjaan 
- Housing = Status kepemilikan rumah 
- Saving accounts = Rekening Tabungan
- Checking account = Rekening Giro
- Credit amount = Jumlah Pinjaman 
- Duration = Waktu Pinjaman
- Purpose = Alasan peminjaman

**Memeriksa Missing Value**

---
Memeriksa dataset untuk mengetahui apakah dataset memiliki missing value. Berdasarkan hasil analisis, terdapat missing value pada kolum **Saving account** dan **Checking account**.
"""

df.info()

df.describe()

#Checking and Filling Null Values
print(df.isnull().sum(axis=0))
df = df.fillna('No Account')

"""**Membuat Kategori untuk Age, Credit_amount dan Duration**

---
Karena jumlah angka unik pada ketiga fitur tersebut sangat besar, maka akan dilakukan pengelompokan fitur pada **Age, Credit_amount dan Duration**.
"""

#Age
interval = (18, 25, 35, 60, 75)
cats = ['Student', 'Young', 'Adult', 'Senior']
df["Age_category"] = pd.cut(df.Age, interval, labels=cats)
df[['Age_category']] = df[['Age_category']].astype('object')

# Credit_amount
interval = (200, 1500, 2500, 4000, 18500)
cats = ['Low', 'Lower_Middle', 'Upper_Middle', 'High']
df["Credit_category"] = pd.cut(df.Credit_amount, interval, labels=cats)
df[['Credit_category']] = df[['Credit_category']].astype('object')

# Duration
interval = (0, 12, 18, 24, 73)
cats = ['Short', 'Lower_Middle', 'Upper_Middle', 'Long']
df["Duration_category"] = pd.cut(df.Duration, interval, labels=cats)
df[['Duration_category']] = df[['Duration_category']].astype('object')

df.info()

#Checking for the uniqe values in the categorical columns
categorical = ["Sex","Job","Housing","Saving_accounts","Checking_account","Purpose", "Age_category", "Credit_category", "Duration_category", "Risk"]
for column in categorical:
    unique_values = df[column].unique()
    print(f'Unique values in column {column}: {unique_values}')

df

"""# Exploratory Data Analysis

**Univariete Analysis**

---
Plot ini memberikan distribusi kelas yang berbeda dan fitur target. Karena jumlah kredit bagus adalah 70% dari kumpulan data, kami mengatakan bahwa kami memiliki **kumpulan data yang tidak seimbang**.
"""

#Hitung Plot untuk Variabel Kategori
def count(column,rot=0):
    counts = df[column].value_counts().sort_values(ascending=False)
    sns.countplot(x=column,data=df, order=counts.index)
    plt.xlabel(f"{column}")
    plt.ylabel("Frequenecy of Occurence")
    plt.title(f"Countplot for {column}")
    plt.xticks(rotation=rot)
    plt.show()
    index = []
    values = []
    distribution = []
    for idx, value in enumerate(counts):
      index.append(counts.index[idx])
      values.append(value)
      distribution.append(str(round(value/sum(counts)*100, 2))+"%")
    dist = pd.DataFrame(list(zip(values, distribution)), index =index,columns =['Value', 'Distribution'])
    print(dist)

for column in categorical:
    if column=="Purpose":
        count(column,90)
    else:
        count(column)

#Fungsi untuk memplot distribusi fitur berkelanjutan
def hist(column,bins=20):
    sns.histplot(x=column,data=df,bins=bins, color='deepskyblue',kde=True)
    plt.show()

num_columns = ["Age","Duration","Credit_amount"]
for column in num_columns:
    hist(column)

"""Pada ketiga fitur tersebut distribusi memiliki Skewed Positive

**Multivariete Analysis**

---
Melihat hubungan antara fitur kategorikal dengan risiko kegagalan pembayaran
"""

#Memeriksa berbagai kolom kategori sambil membandingkan dengan kelas target
def bivariate(column,rot=0):
    sns.countplot(x=column, hue="Risk", data=df)
    plt.xticks(rotation=rot)
    plt.show()
    for cat in df[column].unique():
        x = len(df[(df[col]==cat) & (df['Risk']=='bad')])/len(df[(df[col]==cat)])*100
        print(f"Percentage of {cat} with Bad Loans: {x:.2f}%")

for col in categorical:
    if col == "Risk":
        pass
    elif col == "Purpose":
        bivariate(col,90)
    else:
        bivariate(col)

"""**Descriptive Statistics**

---
Analisis deskriptif membantu mendeteksi adanya outlier, serta membantu kita mengidentifikasi adanya dugaan asosiasi pada variabel.
"""

sns.boxplot(y="Purpose",x="Credit_amount",data=df)

#Di sini kami menganalisis outlier jumlah kredit untuk kategori dalam fitur tujuan
def outlier_analysis(cat):
    df_a = df["Credit_amount"].loc[df["Purpose"]==cat]
    out_l = df_a.quantile(0.75) + 1.5*(df_a.quantile(0.75) - df_a.quantile(0.25))
    df_b = df[(df["Purpose"]==cat) & (df["Credit_amount"]>out_l)]
    display(df_b)
    percent = len(df_b.loc[df_b["Risk"]=="bad"])*100/len(df_b)
    print(f"Percentage of Bad Loans for {cat} where the credit amount lies in the oulier range: {percent:.2f}%")

outlier_analysis("radio/TV")

outlier_analysis("car")

"""Dari sini kita bisa melihat ketika orang mengambil jumlah kredit yang berada di kisaran outlier untuk tujuan tertentu seperti pembelian **Mobil atau Furnitur** memiliki ketimpangan mencapai 60-80% sementara untuk beberapa tujuan seperti pembelian **Radio/TV atau Pendidikan** masih berada diantara nilai yang sama."""

#Crosstab plot untuk melihat tujuan apa yang dipinjamkan oleh setiap jenis kelamin
date_int = ["Purpose", 'Sex']
pd.crosstab(df[date_int[0]], df[date_int[1]]).style.background_gradient(cmap = "viridis")

"""Dari crosstab plot kita melihat bahwa **lebih banyak perempuan mengambil pinjaman untuk pendidikan** daripada laki-laki dan **lebih banyak laki-laki mengambil pinjaman untuk mobil daripada perempuan**.

**Correlation b/w variables**

---
Matriks Korelasi untuk Variabel Kontinu
"""

#Replace good/bad with 0/1
df['Risk'] = df['Risk'].replace({'bad': 0, 'good': 1})

#Correlation Matrix for Continous Variables
corr_matrix = df.corr()
sns.heatmap(corr_matrix, cmap='coolwarm', annot=True)

#Chi-Squared-tes untuk menemukan apakah ada korelasi antara fitur risk dan kategori
def target_corr(col):
    contingency_table = pd.crosstab(df['Risk'], df[col])
    chi2, p_value, dof, expected_freq = chi2_contingency(contingency_table)
    if(p_value>0.05):
        print(f"No correlation b/w the target variable and {col}")
    else:
        print(f"Significant correlation b/w target and {col}")
        print(p_value)

#Hasil untuk berbagai fitur
for col in categorical:
    if col == "Risk":
        pass
    else:
        target_corr(col)

#Chi-Squared-test untuk menemukan korelasi antara fitur kategori independen
def multi_corr(col1,col2):
    contingency_table = pd.crosstab(df[col1], df[col2])
    chi2, p_value, dof, expected_freq = chi2_contingency(contingency_table)
    if(p_value>0.05):
        print(f"No correlation b/w the {col1} and {col2}")
    else:
        print(f"Significant correlation {col1} and {col2}")

#Results
multi_corr('Sex','Housing')
multi_corr('Housing','Checking_account')
multi_corr('Housing','Saving_accounts')
multi_corr("Saving_accounts","Checking_account")
multi_corr('Age_category','Sex')
multi_corr('Age_category','Checking_account')
multi_corr('Age_category','Housing')
multi_corr('Credit_category','Sex')
multi_corr('Credit_category','Checking_account')
multi_corr('Credit_category','Saving_accounts')
multi_corr('Credit_category','Housing')
multi_corr('Duration_category','Saving_accounts')

"""**Melakukan one hot encoding**

---
Melakukan one hot encoding pada seluruh data kategorikal
"""

#One-Hot Encoding the Sex and Checking Account
one_hot = pd.get_dummies(df, columns=['Sex', 'Checking_account', 'Age_category', 'Credit_category', 'Duration_category'])

#Dropping columns which are not correlated with target or significantly correlated with some other feature
one_hot = one_hot.drop(['Housing', 'Purpose', 'Saving_accounts'], axis=1)
#Log Transforming the continous variables
one_hot['Duration'] = np.log(one_hot['Duration'])
one_hot['Credit_amount'] = np.log(one_hot['Credit_amount'])
one_hot['Age'] = np.log(one_hot['Age'])

"""**Cek data setelah one hot encoding**

---
Melihat 5 data pertama setelah melakukan one-hot-encoding
"""

one_hot.head()

one_hot.describe()

"""# Modeling"""

# Memisahkan fitur dan vektor target
one_hot = one_hot.reindex(columns=[col for col in one_hot.columns if col != 'Risk'] + ['Risk'])
X = one_hot.iloc[:,:-1]
y = one_hot.iloc[:,-1]

one_hot

#Oversampling menggunakan SMOTE
from imblearn.over_sampling import SMOTE
oversample = SMOTE()
X_smote, y_smote = oversample.fit_resample(X, y)

#Train test split
X_train, X_test, y_train, y_test = train_test_split(X_smote,y_smote,test_size=0.2,random_state=4)
X_train.shape, X_test.shape

# to feed the random state
seed = 7

# prepare models
models = []
models.append(('LGR', LogisticRegression()))
models.append(('LDA', LinearDiscriminantAnalysis()))
models.append(('KNN', KNeighborsClassifier()))
models.append(('CART', DecisionTreeClassifier()))
models.append(('NB', GaussianNB()))
models.append(('RF', RandomForestClassifier()))
models.append(('SVM', SVC(gamma='auto')))
models.append(('XGBM', XGBClassifier()))
models.append(('LGBM', LGBMClassifier()))


# evaluate each model in turn
results = []
names = []
scoring = 'recall'

for name, model in models:
  kfold = KFold(n_splits=10, random_state=seed, shuffle=True)
  cv_results = cross_val_score(model, X_train, y_train, cv=kfold, scoring=scoring)
  results.append(cv_results)
  names.append(name)
  msg = "%s: %f (%f)" % (name, cv_results.mean(), cv_results.std())
  print(msg)
        
# boxplot algorithm comparison
fig = plt.figure(figsize=(11,6))
fig.suptitle('Algorithms Compare')
ax = fig.add_subplot(111)
green_diamond = dict(markerfacecolor='g', marker='D')
plt.boxplot(results, flierprops=green_diamond, patch_artist=True)
ax.set_xticklabels(names)
plt.show()

"""**Linear Discriminant Analysis Model**

---
Melakukan hypertuning parameter dan evaluasi pada Linear Discriminant Model
"""

# model tuning
lda = LinearDiscriminantAnalysis()
# Set the ranges of hyperparameters to optimize
parameters = {
    'solver': ['lsqr'],
    'shrinkage': [None] + [x / 10 for x in range(0, 11)] + ['auto'],
    'n_components': [None] + [1, 2, 5, 8, 13, 21, 34, 55],
    'store_covariance': [True, False],
    'tol': [1e-2, 1e-3, 1e-4, 1e-5, 1e-6, 1e-7, 1e-8, 1e-9, 1e-10, 1e-11, 1e-12, 1e-13, 1e-14, 1e-15]}

#GridSearchCV method
gs_cv = GridSearchCV(lda,
                     parameters,
                     cv=5,                                  # i did cv=5 this is not enough and this is for faster estimate
                     n_jobs=-1,
                     verbose=2).fit(X_train, y_train)

plot_grid_search(gs_cv)
table_grid_search(gs_cv)

#En iyi parametrelerle model kurma
lda_tuned = LinearDiscriminantAnalysis(**gs_cv.best_params_).fit(X, y)
cross_val_score(lda_tuned, X_test, y_test, cv=10).mean()

#cv islemleri(caprazlama)
kfold = KFold(n_splits=10, random_state=123, shuffle=True)
cv_results = cross_val_score(LinearDiscriminantAnalysis(), X_train, y_train, cv=kfold, scoring="accuracy")
cv_results.mean()
gs_cv.best_estimator_

from sklearn.utils import resample
from sklearn.metrics import roc_curve

# Fitting with train data
model = lda_tuned.fit(X_train, y_train)
labels = ['Bad', 'Good']
print("Primitive error evaluation accuracy score: ", model.score(X_train, y_train))

y_pred = model.predict(X_test)

print("Test predict accuracy score: ", accuracy_score(y_test,y_pred),"\n")

print("Confussion Matrix: \n", confusion_matrix(y_test, y_pred),"\n")

print("Classification report according to Test prediction: \n", classification_report(y_test, y_pred))

# Plotting a Confusion Matrix in Seaborn
conf_matrix = confusion_matrix(y_test, y_pred, labels=model.classes_)
sns.heatmap(conf_matrix,
            annot=True,
            fmt='g',
            xticklabels=labels,
            yticklabels=labels,
    )
plt.ylabel('Prediction',fontsize=13)
plt.xlabel('Actual',fontsize=13)
plt.title('Confusion Matrix',fontsize=17)
plt.show()

#Predicting proba
y_pred_prob = model.predict_proba(X_test)[:,1]

# Generate ROC curve values: fpr, tpr, thresholds
fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)

# Plot ROC curve
plt.plot([0, 1], [0, 1], 'k--')
plt.plot(fpr, tpr)
plt.xlabel('False Positive Rate', color="r")
plt.ylabel('True Positive Rate', color="g")
plt.title('ROC Curve')
plt.show()

"""**LightGBM Model**

---
Melakukan hypertuning parameter dan evaluasi pada LightGBM Model
"""

# model tuning

lgbm = LGBMClassifier()
lgbm_params = {"learning_rate": [0.01, 0.03, 0.05, 0.1, 0.5],
               "n_estimators": [500, 1000, 1500],
               "max_depth": [3,5,8]}

#GridSearchCV method
gs_cv = GridSearchCV(lgbm,
                     lgbm_params,
                     cv=5,                                  # i did cv=5 this is not enough and this is for faster estimate
                     n_jobs=-1,
                     verbose=2).fit(X_train, y_train)

plot_grid_search(gs_cv)
table_grid_search(gs_cv)
#En iyi parametrelerle model kurma
lgbm_tuned = LGBMClassifier(**gs_cv.best_params_).fit(X, y)
cross_val_score(lgbm_tuned, X_test, y_test, cv=10).mean()

#cv islemleri(caprazlama)
kfold = KFold(n_splits=10, random_state=123, shuffle=True)
cv_results = cross_val_score(LGBMClassifier(), X_train, y_train, cv=kfold, scoring="accuracy")
cv_results.mean()

gs_cv.best_estimator_

print("Primitive error evaluation accuracy score: ", lgbm_tuned.score(X_train, y_train))

y_pred = lgbm_tuned.predict(X_test)

print("Test predict accuracy score: ", accuracy_score(y_test,y_pred),"\n")

print("Confussion Matrix: \n", confusion_matrix(y_test, y_pred),"\n")

print("Classification report according to Test prediction: \n", classification_report(y_test, y_pred))

# Plotting a Confusion Matrix in Seaborn
conf_matrix = confusion_matrix(y_test, y_pred, labels=lgbm_tuned.classes_)
sns.heatmap(conf_matrix,
            annot=True,
            fmt='g',
            xticklabels=labels,
            yticklabels=labels,
    )
plt.ylabel('Prediction',fontsize=13)
plt.xlabel('Actual',fontsize=13)
plt.title('Confusion Matrix',fontsize=17)
plt.show()

"""**XGBOOST Model**

---
Melakukan hypertuning parameter dan evaluasi pada XGBOOST Model
"""

xgb = XGBClassifier(random_state = 12345)

xgb_params = {
    "learning_rate": [0.01, 0.1, 0.2, 1],
    "min_samples_split": np.linspace(0.1, 0.5, 10),
    "max_depth":[3,5,8],
    "subsample":[0.5, 0.9, 1.0],
    "n_estimators": [100,1000]}

#xgb_cv_model  = GridSearchCV(xgb,xgb_params, cv = 5, n_jobs = -1, verbose = 2).fit(X, y)    # i did cv=5 this is not enough and this is for faster estimate
#xgb_tuned = XGBClassifier(**xgb_cv_model.best_params_).fit(X,y)
xgb = XGBClassifier().fit(X,y)
cross_val_score(xgb, X, y, cv = 10).mean()

print("Primitive error evaluation accuracy score: ", xgb.score(X_train, y_train))

y_pred = xgb.predict(X_test)

print("Test predict accuracy score: ", accuracy_score(y_test,y_pred),"\n")

print("Confussion Matrix: \n", confusion_matrix(y_test, y_pred),"\n")

print("Classification report according to Test prediction: \n", classification_report(y_test, y_pred))

# Plotting a Confusion Matrix in Seaborn
conf_matrix = confusion_matrix(y_test, y_pred, labels=xgb.classes_)
sns.heatmap(conf_matrix,
            annot=True,
            fmt='g',
            xticklabels=labels,
            yticklabels=labels,
    )
plt.ylabel('Prediction',fontsize=13)
plt.xlabel('Actual',fontsize=13)
plt.title('Confusion Matrix',fontsize=17)
plt.show()

"""**Kesimpulan**

---
Hasil Modeling risiko kegagalan bayar peminjaman menggunakan **Linear Discriminat Analysis Model**, **LightGBM Model**, dan **XGBOOST Model** menghasilkan model yang lebih baik menggunakan **XGBOOST Model** dengan tingkat akurasi mencapai 90% Dibandingkan dengan yang lainnya. Hal ini menyimpulkan bahwa model yang telah dibangun sudah cukup baik dalam mengenali pattern dari kegagalan bayar dari suatu peminjaman.
"""